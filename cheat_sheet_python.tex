\documentclass[%
	11pt,
	a4paper,
	utf8,
	%twocolumn
		]{article}	

\usepackage{style_packages/podvoyskiy_article_extended}


\begin{document}
\title{Некоторые вопросы программирования на языке Python и приемы работы со специализированными библиотеками}

\author{}

\date{}
\maketitle

\thispagestyle{fancy}

\tableofcontents

\section{Терминология}

Любой элемент данных, используемый в программе на Python, является \emph{объектом} \cite[\strbook{57}]{beazley:python-2010}.

Каждый объект имеет свою:
\begin{itemize}
	\item идентичность,
	
	\item тип (или класс),
	
	\item значение.
\end{itemize}

Например, когда в программе встречается интсрукция \verb|a = 42|, интерпретатор создает целочисленный объект со значением 42. Можно рассматривать идентичность объекта как указатель на область памяти, где находится объект, а индентификатор \texttt{a} -- как имя, которое ссылается на эту область памяти.

\emph{Тип объекта} сам по себе является \emph{объектом}, который называется \emph{классом объекта}. Все объекты в яызке Python могут быть отнесены к \emph{объектам первого класса} \cite[\strbook{61}]{beazley:python-2010}. Это означает, что все объекты, имеющие идентификатор, можно интерпретировать как \emph{данные}.

Тип \texttt{None} используется для представления пустых объектов (т.е. объектов, не имеющих значений). Этот объект возвращается функциями, которые не имеют явно возвращаемого значения. Объект \texttt{None} часто используется как значение по умолчанию для необязательных аргументов. Объкт \texttt{None} не имеет атрибутов и в логическом контексте оценивается как значение \texttt{False}.

\emph{Функции}, \emph{классы} и \emph{модули} в языке Python являются объектами, которыми можно манипулировать как обычными данными.

\emph{Свободные переменные} -- переменные, которые были определены в объемлющих функциях, а используются вложенными функциями \cite[\strbook{81}]{beazley:python-2010}.

Все функциональные возможности языка, включая присваивание значений переменным, определение функций и классов, импортирование модулей, реализованы в виде инструкций, обладающих равным положением со всеми остальными инструкциями.

\section{Соглашения по именованию классов, функций и переменных}

Шаблон именования функции (P)A/HC/LC
\begin{lstlisting}[
style = bash,
numbers = none
]
префикс? (P) + действие (A) + высокоуровневый контекст (HC) + низкоуровневый контекст (LC)
\end{lstlisting}

\section{Приемы работы с пакетом Nox}

\subsection{Общий шаблон}

Nox \url{https://nox.thea.codes/en/stable/index.html} -- библиотека и утилита командной строки для автоматизации различных процедур в мульти-средах Python -- от простого запуска тестов с помощью, например, \verb|pytest|, линтеров или сборщиков Docker-образов и до запуска цепочек выполнения произвольной сложности.

Если говорить о Python-сцериях, то в файле \verb|noxfile.py| описывается только процедура запуска сценария (вызов сценрия из оболочки), а не сам сценарий.

Для запуска утилиты \verb|nox| требуется подговтоить файл \verb|noxfile.py| и положить его в корень проекта
\begin{lstlisting}[
title = {\sffamily noxfile.py},
style = ironpython,
numbers = none	
]
import nox


nox.needs_version = ">=2019.5.30"
nox.options.default_venv_backend = "conda"

@nox.session(python=False)
def docker(session):
	session.run(
		"sudo", "docker", "build",
		"--build-arg", "USER_ID=1000",
		"--build-arg", "GROUP_ID=1000",
		"--build-arg", "STRATEGY_NAME=fix_bins_ints_in_relax_sol",
		"--build-arg", "PATH_TO_STRATEGIES_DIR=./data/strategies",
		"-t", "tthec-fix_bins_ints_in_relax_sol",
		"."
	)

@nox.session(
    python=["3.8", "3.9", "3.10"],  # тесты выполняются для 3-х версий Python
    venv_backend="conda",
    reuse_venv=True,
)
def test(session):
    # conda ставит только PySCIPOpt==4.3.0 с канала conda-forge
    session.conda_install("pyscipopt==4.3.0", channel="conda-forge")
    # --no-deps, чтобы не сломать окружение conda
    session.install("--no-deps", "-r", "requirements.txt")
    session.run(
        "pytest",
        "-v",
        "-k", "solver",  #запускает только те тесты, в имени которых есть подстрока 'solver'
        env = {  # здесь описываются переменные окружения
            "PYTHONPATH": "./src",  # как если бы запускали $ PYTHONPATH=./src pytest
        }
    )
\end{lstlisting}

Теперь для запуска сессии сборки образа нужно просто запустить утилиту с указанием имени сессии
\begin{lstlisting}[
style = bash,
numbers = none
]
$ nox -s docker
\end{lstlisting}

То есть в файле \verb|noxfile.py| можно описывать любые сессии, которые автоматизируют различные задачи (запуск тестов, сборку Docker-образов и пр.) и доступ к этим сессиям будет, так сказать, с одной точки.

Можно запускать цепочки
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import nox
import pathlib2

# NOX OPTIONS
nox.needs_version = ">=2022"
nox.options.default_venv_backend = "conda"

# PROJECT PARAMS
STRATEGY_NAME = "fix_bins_ints_in_relax_sol_with_perturbation"
PROBLEM_FILE_NAME = "model_MNPZ_march_no_plecho_no_CDO_only_BRN.mps"

PATH_TO_DATA_DIR = Path().joinpath("data/").absolute()
PATH_TO_PROBLEMS_DIR = PATH_TO_DATA_DIR.joinpath("problems/")
PATH_TO_MAKE_STRATEGY_FILE = Path("./src/strategy_templates/make_strategy_file.py")
PATH_TO_SETTINGS_DIR = PATH_TO_DATA_DIR.joinpath("settings/")
PATH_TO_RELAX_SET_FILE = PATH_TO_SETTINGS_DIR.joinpath("scip_relax.set")
PATH_TO_MILP_SET_FILE = PATH_TO_SETTINGS_DIR.joinpath("scip_milp.set")
PATH_TO_STRATEGIES_DIR_HOST = PATH_TO_DATA_DIR.joinpath("strategies/")
PATH_TO_STRATEGIES_DIR_CONTAINER = "./data/strategies"

DOCKER_MEMORY = 8000  # Mb
DOCKER_MEMORY_SWAP = 8000  # Mb

DEFAULT_INTERPRETER = "3.8"
TARGET_INTERPRETERS = ("3.8", "3.9", "3.10")

# ENVS
env = {"PYTHONPATH": "./src"}

@nox.session(python=False)
def run_app_with_docker(session):
	session.run(
		"sudo", "docker", "build",
		"--build-arg", "USER_ID=1000",
		"--build-arg", "GROUP_ID=1000",
		"--build-arg", "STRATEGY_NAME=fix_bins_ints_in_relax_sol",
		"--build-arg", "PATH_TO_STRATEGIES_DIR=./data/strategies",
		"-t", "tthec-fix_bins_ints_in_relax_sol",
		"."  # контекст
	)
	# вызов следующего вспомогательного сценария
	session.notify("make_strategy_file")
	
@nox.session(python=DEFAULT_INTERPRETER)
def make_strategy_file(session):
    session.install("pathlib2>=2.3.7")
    session.run(
	    "python", PATH_TO_MAKE_STRATEGY_FILE,
	    "--strategy-name", STRATEGY_NAME,
	    "--path-to-relax-set-file", PATH_TO_RELAX_SET_FILE,
	    "--path-to-milp-set-file", PATH_TO_MILP_SET_FILE,
	    "--path-to-test-problem-file", PATH_TO_PROBLEMS_DIR.joinpath(PROBLEM_FILE_NAME),
	    "--path-to-strategies-dir", PATH_TO_STRATEGIES_DIR_HOST,
	    env=env,
    )
    # вызов следующего вспомогательного сценария
    session.notify("docker_run")
    
@nox.session(python=False)
def docker_run(session):
	session.run(
		"sudo", "docker", "run",
		"--rm",
		"-v", f"{PATH_TO_DATA_DIR}:/data",
		"-m", f"{DOCKER_MEMORY}m",
		"--memory-swap", f"{DOCKER_MEMORY_SWAP}m",
		f"tthec-{STRATEGY_NAME}"
	)
...
\end{lstlisting}

Запуск цепочки
\begin{lstlisting}[
style = bash,
numbers = none
]
$ nox -s run_app_with_docker
\end{lstlisting}

Чтобы захватить вывод команды оболочки, нужно у метода \verb|run| выставить \verb|silent=True|
\begin{lstlisting}[
style = bash,
numbers = none
]
@nox.session(python=False)
def f(session):
	USER_ID = session.run("bash", "-c", "echo $(id -u)", silent=True)
	GROUP_ID = session.run("bash", "-c", "echo $(id -g)", silent=True)
	...
\end{lstlisting}

\subsection{Запуск тестов в мультисредах Python}

Для того чтобы запустить тесты сразу для нескольких версий интерпретатора достаточно просто передать список нужных версий декоратору \verb|@nox.session(python=["3.8", "3.9", ...])|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
@nox.session(
    python=["3.8", "3.9"],
    venv_backend="conda",
    reuse_venv=False,
)
def test(session):
    session.conda_install("pyscipopt==4.3.0", channel="conda-forge")
    session.install("--no-deps", "-r", "requirements.txt")
    
    session.run(
        "pytest",
        "-v",
        env={"PYTHONPATH": "./src"}
    )
\end{lstlisting}

\subsection{Nox как утилита командной строки}

\url{https://nox.thea.codes/en/stable/usage.html}

Вывести список сессий
\begin{lstlisting}[
style = bash,
numbers = none
]
$ nox -l
* test-3.8
* test-3.9
* test-3.10
\end{lstlisting}

Запустить только тестирование для Python 3.10
\begin{lstlisting}[
style = bash,
numbers = none
]
$ nox --session test-3.10  # или с коротким флагом '-s'
\end{lstlisting}

После запуска сессий по умолчанию в текущей директории создается скрытая директория \verb|.nox|, в которую записывается сводка по запускам. Чтобы создать эту сводку в указанном пользователем месте, нужно использовать флаг \verb|--envdir|
\begin{lstlisting}[
style = bash,
numbers = none
]
$ nox --envdir /tmp/envs
\end{lstlisting}

Утилите \verb|nox| можно передать позиционные аргументы
\begin{lstlisting}[
style = bash,
numbers = none
]
...
@nox.session
def test(session):
    if session.posargs:
        test_files = session.posargs
    else:
        test_files = ["test_a.py", "test_b.py"]
        
   session.run("pytest", *test_files)
   
$ nox -- test_c.py
\end{lstlisting}

Еще один важный момент заключается в том, что если требуется управлять цепочкой выполнения по условию, то можно пробросить значения аргументов командной строки через аргумент \verb|posargs| функции \verb|notify|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
@nox.session(python=DEFAULT_INTERPRETER)
def fake1(session):
    args: t.List[str] = session.posargs
    
    if args and ("docker" in args):
        use_docker = True
    else:
        use_docker = False
        
    session.notify("fake2", posargs=[use_docker])  # пробрасываем значение аргумента
    
@nox.session(python=DEFAULT_INTERPRETER)
def fake2(session):
    print(session.posargs)
\end{lstlisting}

Теперь можно вызвать сессию так
\begin{lstlisting}[
style = bash,
numbers = none
]
$ nox -s fake1 -- docker
\end{lstlisting}

ВАЖНО: Не обязательно пробрасывать значения аргумента через все элементы цепочки. Значение аргумента, переданное в <<головной>> элемент цепочки, можно прочитать в любом другом элементе как \verb|session.posargs|


\section{Приемы работы с pip}

С одной стороны в виртуальное окружение conda можно устанавливать пакеты с помощью менеджера \verb|pip|, но все-таки лучше с \verb|pip| использовать флаг \verb|--no-deps|. Это поможет не сломать окружение \verb|conda|. В противном случае пакеты устанавливаемые с помощью \verb|pip| могут получить несовместимые версии с пакетами уже установленными в окружении conda \url{https://nox.thea.codes/en/stable/tutorial.html}
\begin{lstlisting}[
style = bash,
numbers = none	
]
$ pip install --no-deps -r req.txt
\end{lstlisting}

\section{Приемы работы с pytest}

\subsection{Особенности импорта}

Пусковой сценарий проекта обычно располагается в директории \verb|./src|. В этом случае сканирование окружения на предмет поиска пользовательских пакетов и модулей начинается с той директории, в которой \emph{лежит} этот пусковой сценарий, то есть с директории \verb|./src|
\begin{lstlisting}[
style = bash,
numbers = none
]
project_root/
    src/
        common/  # пакет
            __init__.py
            logger.py
            exceptoins.py
        units/  # пакет
            __init__.py
            fix_vars.py
            base_unit.py
            solver.py
        strategy_manager.py
        run.py
\end{lstlisting}

Тогда импорт в самом сценарии может выглядеть так
\begin{lstlisting}[
title = {\sffamily run.py},
style = ironpython,
numbers = none
]
# путь отсчитывается от той директории, в которой лежит run.py
from common.logger import make_logger
from strategy_manager import StrategyManager
...
\end{lstlisting}

В модулях пути тоже отсчитываются от той директории, в которой \emph{лежит} пусковой сценарий
\begin{lstlisting}[
title = {\sffamily solver.py},
style = ironpython,
numbers = none
]
from common.logger import make_logger
from units.base_unit import Unit
...
\end{lstlisting}

В тестах можно указывать пути от той же директории \verb|./src|, то есть
\begin{lstlisting}[
title = {\sffamily test\_solver.py},
style = ironpython,
numbers = none
]
import pytest
# путь отсчитывается от директории ./src
from common.exceptions import HiGHS
from units.solver import Solver

@pytest.mark.unit
def test_solver_unit_highs_with_unsupported_solver_name():
    ...
\end{lstlisting}

Но запускать тесты нужно будет так
\begin{lstlisting}[
style = bash,
numbers = none
]
# требуется включить директорию ./src в список путей поиска
$ PYTHONPATH=./src pytest -v
$ PYTHONPATH=./src pytest -v --cov=. --cov-report=html
\end{lstlisting}

\section{Метод \texttt{\_\_repr\_\_}}

Метод \verb|__repr__| предназначен для вывода полезной информации на шаге отладки, а метод \verb|__str__| -- вывода полезной информации для пользователей. При этом принято, чтобы метод \verb|__repr__| возвращал такую строку, обернув которую функцией \verb|eval()|, можно было получить экземпляр класса.
	
Для того чтобы специальный метод \verb|__repr__| мог аккуратно выводить сигнатуру класса удобно воспользоваться модулем \verb|inspect|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import inspect

class MyClass:
    def __init__(self, name: str, age: int):
        self.name = name
        self.age = age
        
    def __repr__(self):
        _args: t.List[str] = []
        # аргументы класса: name и age
        _class_args = tuple(inspect.signature(type(self)).parameters.keys())
        _obj_attrs = self.__dict__
        
        for key, value in _obj_attrs.items():
            if key in _class_args:
                # обязательно использовать сырое форматироваие !r
                _args.append(f"{key}={value!r}")  
        args = ", ".join(_args)
        
        return f"{type(self).__name__}({args})
\end{lstlisting}
		
		

\section{Замечание о пользовательских пакетах}

При написании пользовательских пакетах файл зависимостей должен быть как можно менее ограничительным
\begin{lstlisting}[
title = {\sffamily requirements.txt},
style = ironpython,
numbers = none
]
# Data
numpy >= 1.16.0, !=1.24.0
pandas >= 1.1.0, < 1.3.0; python_version == '3.7'
pandas >= 1.3.0; python_version >= '3.8'
scipy >= 1.9.3; python_version >= '3.8'

# Parallelization
joblib >= 1.2.0; python_version >= '3.8'

# Models and frameworks
scikit-learn >= 1.0.0; python_version >= '3.8'
pyod >= 1.0.7; python_version >= '3.8'

# Optimization and solvers
# pyomo >= 6.4.2; python_version >= '3.8'
# PySCIPOpt installed using environment.yaml file of conda package manager
pyscipopt >= 4.3.0; python_version == '3.8'

# Plotting
matplotlib >= 3.3.1; python_version >= '3.8'

# Misc
pathlib2 >= 2.3.7
python-dotenv >= 0.21.0
pyyaml >= 6.0
tqdm
psutil >= 5.7.3

# Tests
pytest >= 6.2.0
\end{lstlisting}

Файл \verb|setup.py| может выглядеть так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
rom pathlib import Path
from typing import List

import setuptools

# The directory containing this file
HERE = Path(__file__).parent.resolve()

# The text of the README file
NAME = "zyopt"
VERSION = "0.0.1"
AUTHOR = "Digital Industrial Platform"
SHORT_DESCRIPTION = (
	"Add-in for the SCIP solver with support for heuristics, "
	"classical machine learning and deep learning methods"
)
README = Path(HERE, "README.md").read_text(encoding="utf-8")
URL = ""
REQUIRES_PYTHON = ">=3.8"
LICENSE = "BSD 3-Clause"


def _readlines(*names: str, **kwargs) -> List[str]:
	encoding = kwargs.get("encoding", "utf-8")
	lines = Path(__file__).parent.joinpath(*names).read_text(encoding=encoding).splitlines()
	return list(map(str.strip, lines))


def _extract_requirements(file_name: str):
	return [line for line in _readlines(file_name) if line and not line.startswith("#")]


def _get_requirements(req_name: str):
	requirements = _extract_requirements(req_name)
	return requirements


setuptools.setup(
	name=NAME,
	version=VERSION,
	author=AUTHOR,
	author_email="itmo.nss.team@gmail.com",
	description=SHORT_DESCRIPTION,
	long_description=README,
	long_description_content_type="text/x-rst",
	url=URL,
	python_requires=REQUIRES_PYTHON,
	license=LICENSE,
	packages=setuptools.find_packages(exclude=["test*"]),
	include_package_data=True,
	install_requires=_get_requirements("requirements.txt"),
	classifiers=[
		"License :: OSI Approved :: BSD License",
		"Programming Language :: Python :: 3.8",
		"Programming Language :: Python :: 3.9",
		"Programming Language :: Python :: 3.10",
	],
)
\end{lstlisting}

Сборка выполняется в корне проекта
\begin{lstlisting}[
style = bash,
numbers = none
]
$ python setup.py sdist bdist_wheel
\end{lstlisting}

Если все прошло успешно, то теперь можно опубликовать пакет на TestPyPI с помощью утилиты \verb|twine|
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
$ twine upload -r testpypi dist/* --verbose
\end{lstlisting}

Посмотреть, что получилось можно на \verb|https://test.pypi.org/project/my_prjoect_name/|. Для проверки работоспособности пакета нужно его поставить на локальную машину
\begin{lstlisting}[
style = bash,
numbers = none
]
$ pip install --index-url https://test.pypi.org/simple/ \
    --extra-index-url https://pypi.org/simple my_package_name
\end{lstlisting}

ВАЖНО! Флаг \verb|--extra-index-url| нужен, чтобы \verb|pip| мог при установке извлекать зависимости с PyPI.

И, наконец, если все устраивает, то можно опубликовать пакет на PyPI
\begin{lstlisting}[
style = bash,
numbers = none
]
$ twine upload dist/*
\end{lstlisting}


\section{Инвариантность, ковариантность и контрвариантность}

Ковариантность позволяет использовать переданный тип или его дочерние типы, инвариантность -- тот только тип, который передали, а контрвариативность -- более общие типы.
Функции являются \emph{контрвариантными} к своим аргументам и \emph{ковариантными} к результатам. В общем случае контравариантность имеет смысл использовать для входных значений, получаемых объектами, и ковариантность -- для выходных значений. Если объект допускает и то, и другое, тип следует оставить \emph{инвариантным}. В общем случае инвариантность свойственна \emph{изменяемым} структурам данных (списки в Python инвариантны). Параметры методов являются контравариантными позициями, а возвращаемые типы -- ковариантными. Однако в внутри функции вариантность параметров изменяется, -- они становятся ковариантными \cite[\strbook{320}]{hostmann:scala-2013}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from collection.abc import Callable

def give_task_for_programmer(
    task: Callable[[Programmer], None],  # контравариантная позиция -
    programmer: Programmer,              # контравариантная позиция -
) -> None:
    task(programmer)

def task_for_programmer(programmer: Programmer):
    pass

def task_for_employee(employee: Employee):
    pass

def task_for_frontender(frontender: Frontender):
    pass

# Все нормально! Передаем родительский тип типа Programmer
give_task_for_programmer(
	task_for_programmer,  # ожидается Callable[[Programmer], None], передается Callable[[Programmer], None]
	programmer
)

# Все нормально! Передаем родительский тип типа Programmer
give_task_for_programmer(
    task_for_employee,  # ожидается Callable[[Programmer], None], передается Callable[[Employee], None]
	programmer
)

# Ошибка!!! Передаем дочерний тип типа Programmer
give_task_for_programmer(
    task_for_frontender,  # ожидается Callable[[Programmer], None], передается Callable[[Frontender], None] 
	programmer
)
\end{lstlisting}

\verb|collection.abc.Sequence| -- это неизменяемая структура, поэтому она ковариантна, а списки -- изменяемые структуры, поэтому они инвариантны.

\section{Передача параметров и возвращаемые значения}

Параметры функции, которые передаются ей при вызове, являются \emph{обычными именами}, ссылающимися на \emph{входные объекты}. Семантика передачи параметров в языке Python не имеет точного соответствия какому-либо одному способу, такому как <<передача по значению>> или <<передача по ссылке>>. Например, если функции передается неизменяемое значение, это выглядит, как передача аргумента по значению. Однако при передачи изменяемого объекта (такого как список или словарь), который модифицируется функцией, эти изменения будут отражаться на исходном объекте \cite[\strbook{133}]{beazley:python-2010}.

\section{Правила видимости в функциях}

При каждом вызове функции создается новое локальное пространство имен. Это пространство имен представляет локальное окружение, содержащее имена параметров функции, а также имена переменных, которым были присвоины значения в теле функции. Когда возникает необходимость отыскать имя, интерпретатор в первую очередь просматривает локальное пространство имен. Если искомое имя не было найдено, поиск продолжается в глобальном пространстве имен. Глобальным пространством имен для функций всегда является пространство имен модуля, в котором эта функция была определена. Если интерпретатор не найдет искомое имя в глобальном пространстве имен, поиск будет продолжен во встроенном пространстве имен. Если и эта попытка окажется неудачной, будет возбуждено исключение \texttt{NameError}.

В языке Python поддерживается возможность определять вложенные функции. Переменные во вложенных функциях привязаны к лексической области видимости. То есть поиск имени переменной начинается в \emph{локальной области видимости} и затем последовательно продолжается во всех \emph{объемлющих областях видимости} внешних функций, в направлении от внутренних к внешним. Если и в этих пространствах имен искомое имя не будет найдено, поиск будет продолжен в \emph{глобальном}, а затем во \emph{встроенном пространстве имен}, как и прежде.

При обращении к локальной переменной до того, как ей будет присвоено значение, возбуждается исключение \texttt{UnboundLocalError}
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
i = 0

def foo():
    i = i + 1
    print(i)  # UnboundLocalError
\end{lstlisting}

В функции \texttt{foo} переменная \texttt{i} определяется как локальная переменная, потому что внутри функции ей присваивается некоторое значение и отсутствует инструкция \texttt{global}). При этом инструкция присваивания \texttt{i = i + 1} пытается прочитать значение переменной \texttt{i} еще до того, как ей будет присвоено значение. 

Хотя в этом примере существует глобальная переменная \texttt{i}, она не используется для получения значения. Переменные в функциях могут быть \emph{либо локальными}, \emph{либо глобальными} и не могут произвольно изменять область видимости в середине функции. Например, нельзя считать, что переменная \texttt{i} в выражении \texttt{i = i + 1} в предыдущем фрагменте обращается к глобальной переменной \texttt{i}; при этом переменная \texttt{i} в вызове \texttt{print(i)} подразумевает локальную переменную \texttt{i}, созданную в предыдущей инструкции \cite[\strbook{136}]{beazley:python-2010}.

\section{Функции как объекты и замыкания}

\emph{Функции} в языке Python -- \emph{объекты первого класса}. Это означает, что они могут передаваться другим функциям в виде аргументов, сохраняться в структурах данных и возвращаеться функциями в виде результата \cite[\strbook{136}]{beazley:python-2010}.

Когда инструкции, составляющие функцию, упаковываются вместе с окружением, в котором они выполняются, получившийся объект называют \emph{замыканием}. Такое поведение объясняется наличием у каждой функции атрибута \verb|__globals__|, ссылающегося на глобальное пространство имен, в котором функция была определена. Это пространство имен всегда соответсвтует модулю, в котором функция была объявлена \cite[\strbook{137}]{beazley:python-2010}.

Когда функция используется как вложенная, в замыкание включается все ее окружение, необходимое для работы внутренней функции.

\section{Типизация}

От типов модуля \texttt{typing} можно наследоваться
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
import typing as t
from collection import namedtuple

# Наследуемся от именного кортежа
class Coordinates(t.NamedTuple):
    latit: float
    long: float
    
# Или так
# Но тип поля теперь не указать
# Coordinates = namedtuple("Coordinates", ["latit", "long"])

# Доступ к полям через точечную нотацию
coord = Coordinates(latit=0.45, long=1.45)
coord.latit  # 0.45
coord.long  # 1.45
\end{lstlisting}

Функционально тоже что и дата-класс
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from dataclasses import dataclass

@dataclass(fronzen=False)
class Coordinates:
    latit: float
    long: float
\end{lstlisting}

Именованные кортежы от дата-классов отличаются тем, что именованные кортежи относятся к объектам неизменяемого типа данных. Дата-классы вообще говоря тоже можно сделать неизменяемыми после создания с помощью параметра \verb|frozen=True|.

Именованные кортежи эффективнее с точки зрения хранения. С помощью библиотеки \verb|pympler| \url{https://github.com/pympler/pympler}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import typing as t
from pympler import asizeof

class Coordinates(t.NamedTuple):
    latit: float
    long: float
    
print(asizeof.asized(coord).size)  # 104 Bytes
\end{lstlisting}

Иногда бывает полезно воспользоваться \emph{типизированным словарем} \verb|TypedDict|
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
import typing as t

# Доступ к полям будет как у словаря
class Coordinates(t.TypedDict):
    latit: float
    long: float
    
coord = Coordinates(latit=0.45, long=0.15)
coord["latit"]  # 0.45
coord["long"]  # 0.15
\end{lstlisting}

Еще бывает удобно воспользоваться \emph{перечислением} \verb|Enum|. Модуль \verb|enum| это стандартная часть библиотеки Python, но если по какой-то причине интерпретатор не может его найти, то модуль можно установить так \verb|pip insatll enum|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from enum import Enum

# Перечисление
class FileState(Enum):
    OPENED = "opened"
    CLOSE = "close"
    
FileState.OPENED.value  # opened
\end{lstlisting}

В принципе поведение перечисления можно сымитировать с помощью именованного кортежа
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
import typing as t

class FileState(t.NamedTuple):
    OPENED = "opened"
    CLOSE = "close"
    
FileState.OPENED  # "opened"
\end{lstlisting}

Для неименованных кортежей можно создавать псевдонимы
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# Кортеж с произвольным количеством целых чисел
int_tuple = t.Tuple[int, ...]

def f(*args: int_tuple) -> int:
    return sum(args)
    
print(f(10, 20, 30))  # 60

two_ints = t.Tuple[int, int]
# etc.
\end{lstlisting}

Generic (обобщенные типы)
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import typing as t
T = t.TypeVar("T")  # обобщенный тип

def first(iterable: t.Iterable[T]) -> t.Optional[T]:
    for item in iterable:
        return item
\end{lstlisting}


\section{Модули, пакеты и дистрибутивы}

ВАЖНО: \emph{текущим каталогом} (\verb|os.path.curdir|) будет тот, из-под которого запускается сценарий, но сканирование <<окружающего пространства>> в поисках нужных пользовательских модулей и пр. начинается с той директории, в которой \emph{расположен} сценарий (см. \verb|sys.path|). Если требуется какие-то подмодули сделать доступными через пространство имен пакета с помьщю \verb|__init__.py|, то лучше воспользоваться относительным импортом (он более четко указывает о намерениях).

Можно указывать относительный путь, а можно абсолютный, но от той {директории}, в которой лежит пусковой сценарий (например, \verb|./src/run.py|). То есть, если
\begin{lstlisting}[
style = bash,
numbers = none
]
./  # корень проекта
  src/
    config/  # пакет
      __init__.py
      config.py  # модуль
      ...
\end{lstlisting}
то
\begin{lstlisting}[
title = {\sffamily ./src/config/\_\_init\_\_.py},
style = bash,
numbers = none
]
# поиск начнется со сканирования src/ (потому что здесь лежит пакет config/)
from config.config import Config
# или относительно директории пакета
from .config import Config
\end{lstlisting}

ВАЖНО: в общем случае абсолютный путь в модулях \verb|__init__.py| отсчитывается от директории родительского пакета, то есть от той директории, в которой лежит пусковой сценарий. Этот сценарий указывает от какой директории теперь отсчитываться (не включая эту директорию в пути).

Для сценариев командной оболочки можно явно указать директорию, которая должна просматриваться первой в поисках модулей и пакетов с помощью переменной окружения \verb*|PYTHONPATH|
\begin{lstlisting}[
title = {\sffamily ./src/strategy\_templates/make\_strategy\_file.py},
style = ironpython,
numbers = none
]
from strategy_templates.templates import *
...
\end{lstlisting}

\begin{lstlisting}[
style = bash,
numbers = none
]
# Сканироваться будет директория ./src
PYTHONPATH=./src python ./src/strategy_templates/make_strategy_file.py ...
\end{lstlisting}

Пусковой сценарий удобно располагать в поддиректории проекта \verb|./src|. Если запускать сценарий так \verb|python ./src/run.py|, то сканирование начнется с директории \verb|src| и технически все будет верно, но PyCharm будет подсвечивать пути красным. Чтобы убрать эту красноту, нужно просто объявить \verb|./src| как <<Sources Root>>, кликнув правой кнопкой мыши на директории в дереве проекта и выбрав соответсвующую метку.

Когда инструкция \texttt{import} впервые загружает модуль, она выполняет следующие три операции \cite[\strbook{189}]{beazley:python-2010}:
\begin{enumerate}
	\item Создает новое пространство имен, которое будет служить контейнером для всех объектов, определенных в соответствующем файле.
	
	\item Выполняет программный код в модуле внутри вновь созданного пространства имен.
	
	\item Создает в вызывающей программе имя, ссылающееся на пространство имен модуля. Это имя совпадает с именем модуля.
\end{enumerate}

Когда модуль импортируется впервые, он компилируется в байт-код и сохраняется на диске в файле с расширением \texttt{*.pyc}. При всех последующих обращениях к импортированию этого модуля интепретатор будет загружать скомпилированный байт-код, если только с момента создания байт-кода в файл \texttt{.py} не вносились изменения (в этом случае файл \texttt{.pyc} будет создан заново).

Автоматическая компиляция программного кода в файл с расширением \texttt{.pyc} производиться только при использовании инструкции \texttt{import}. При запуске программ из командной строки этот файл не создается.

\emph{Модули} в языке Python -- это \emph{объекты первого класса} \cite[\strbook{190}]{beazley:python-2010}. То есть они могут присваиваться переменным, помещаться в структуры данных, такие как списки, и передаваться между частями программы в виде элемента данных. Например
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
import pandas as pd
\end{lstlisting}
просто создает переменную \texttt{pd}, которая ссылается на объект модуля \texttt{pandas}.

Важно подчеркнуть, что инструкция \texttt{import} выполнит все инструкции в загруженном файле. Если в дополнение к объявлению переменных, функций и классов в модуле содержаться некоторые вычисления и вывод результатов, то результаты будут выведены на экран в момент загрузки модуля.

Инструкция \texttt{import} может появляться в любом месте программы. Однако программный код любого модуля \emph{загружается} и \emph{выполняется} только один раз, независимо от количества инструкций \texttt{import}. 

\emph{Глобальным пространством имен} для функции всегда будет \emph{модуль}, в котором она была \underline{объявлена}, а не пространство имен, в которое эта функция была импортирована и откуда была вызвана \cite[\strbook{192}]{beazley:python-2010}.

Пакеты позволяют сгруппировать коллекцию модулей под общим именем пакета. Пакет создается как каталог с тем же именем, в котором создается файл с именем \verb|__init__.py|.

Например, пакет может иметь такую структуру
\begin{lstlisting}[
style = bash,
numbers = none
]
graphics/
    __init__.py
    primitives/
        __init__.py
        lines.py
        fill.py
        text.py
        ...
    graph2d/
        __init__.py
        plot2d.py
        ...
    graph3d/
        plot3d.py
        ...
    formats/
        __init__.py
        gif.py
        png.py
        tiff.py
        ...
\end{lstlisting}

Всякий раз когда какая-либо \emph{часть пакета импортируется впервые}, выполняется программный код в файле \verb|__init__.py| \cite[\strbook{198}]{beazley:python-2010}. Этот файл может быть пустым, но может также содержать программный код, выполняющий инициализацию пакета. Выполнены будут все файлы \verb|__init__.py|, которые встретятся инструкции \texttt{import} в процессе ее выполнения.

То есть инструкция
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import graphics.primitives.fill
\end{lstlisting}
сначала выполнит файл \verb|__init__.py| в каталоге \texttt{graphics}, а затем файл \verb|__init__.py| в каталоге \texttt{primitives}.

При импортировании модулей из пакета следует быть особенно внимательными и не использовать инструкцию вида \texttt{import module}, так как в Python 3, инструкция \texttt{import} предполагает, что указан абсолютный путь, и будет пытаться загрузить модуль из стандартной библиотеки. Использование инструкции импортирования по относительному пути более четко говорит о ваших намерениях.

Возможность импортирования по относительному пути можно также использовать для загрузки модулей, находящихся в других каталогах того же пакета. Например, если в модуле \texttt{Graphics.Graph2d.plot2d} потребуется импортировать модуль \texttt{Graphics.Primitives.lines}, инструкция импорта будет иметь следующий вид
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from ..primitives import lines  # так можно!
\end{lstlisting}

В этом примере символы \texttt{..} перемещают точку начала поиска на уровень выше в дереве каталогов, а имя \texttt{primiitves} перемещает ее вниз, в другой каталог пакета.

Импорт по относительному пути может выполняться только при использовании инструкции импортирования вида
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from module import symbol
\end{lstlisting}

То есть такие конструкции, как
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import ..primitives.lines  # Ошибка!
import .lines  # Ошибка!
\end{lstlisting}
будут рассматриваться как синтаксическая ошибка.

Кроме того, имя \texttt{symbol} должно быть допустимым идентификатором. Поэтому такая инструкция, как 
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from .. import primitives.lines  # Ошибка!
\end{lstlisting}
также считается ошибочной.

Наконец, импортирование по относительному пути может выполняться только для модулей в пакете; не допускается использовать эту возможность для ссылки на модули, которые просто находятся в другом каталоге файловой системы.

Импортирование по одному только имени пакета не приводит к импортированию всех модулей, содержащихся в этом пакете \cite[\strbook{199}]{beazley:python-2010}, однако, так как инструкция \texttt{import graphics} выполнит файл \verb|__init__.py| в каталоге \texttt{graphics}, в него можно добавить инструкции импортирования по относительному пути, которые автоматически загрузят все модули, как показано ниже
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# graphics/__init__.py
from . import primitives, graph2d, graph3d

# graphics/primitives/__init__.py
from . import lines, fill, text
...
\end{lstlisting}

Для того чтобы сделать функции модулей подпакетов доступными из-под имени подпакетов (без обращения к модулям, в которых были объявлены эти функции), можно относительный импорт организовать следующим образом
\begin{lstlisting}[
style = ironpython,
numbers =  none
]
# graphics/primitives/__init__.py
from .fill import make_fill
from .lines import make_lines
...
\end{lstlisting}

Теперь вызвать, например, функцию \texttt{make\_fill} модуля \texttt{fill} подпакета \texttt{primitives} можно так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from graphics.primitives import make_fill
# вместо
from graphics.primitives.fill import make_fill
\end{lstlisting}

Грубо говоря, можно считать, что элементы расположенные справа от инструкции \texttt{import} в файле \verb|__init__.py| будут как бы замещать имя модуля \verb|__init__.py| в пути до этого файла, т.е.
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# graphics/formats/__init__.py
from .png import print_png
from .jpg import print_jpg

# В сессии
>>> import graphics.formats.print_png
\end{lstlisting}

Переменная \verb|__all__| управляет логикой работы инструкции \verb|import *| и проявляется только если пользователь модуля/пакета использует прием <<импортировать все>>. Если известен путь до нужного модуля, то переменная \verb|__all__| не помешает. Если определить \verb|__all__| как пустой список, ничего экспортироваться не будет \cite[\strbook{395}]{beazley:python_cookbook-2019}.

Важное замечание: относительное импортирование работает только для модулей, которые размещены внутри подходящего пакета. В частности, оно не работает внутри простых модулей, размещенных на верхнем уровне скриптов. Оно также не работает, если \emph{части пакета} исполняются напрямую, \emph{как скрипты}, например \cite[\strbook{396}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
$ python mypackage/A/spam.py  # Относительное импортирование не работает!!!
\end{lstlisting}

С другой стороны, если вы выполните предыдущий скрипт, передав Python опцию \verb|-m|, относительное импортирование будет работать правильно
\begin{lstlisting}[
style = ironpython,
numbers = none
]
$ python -m mypackage/A/spam  # Относительное импортирование работает!
\end{lstlisting}

\remark{
Относительный импорт не работает, если части пакета исполняются напрямую, как скрипты. Но ситуацияю можно исправить, если воспользоваться опцией \texttt{-m}
}




Наконец, когда интерпретатор импортирует пакет, он объявляет специальную переменную \verb|__path__|, содержащую список каталогов, в которых выполняется поиск модулей пакета (\verb|__path__| представляет собой аналог списка \texttt{sys.path} для пакета). Переменная \verb|__path__| доступна для программного кода в файлах \verb|__init__.py| и изначально содержит единственный элемент с именем каталога пакета.

При необходимости пакет может добавлять в список \verb|__path__| дополнительные каталоги, чтобы изменить путь поиска модулей. Это может потребоваться в случае сложной организации дерева каталогов пакета в файловой системе, которая не совпадает с иерархией пакета.

\subsection{Создание отдельных каталогов с кодом для импорта под общим пространством имен}

Требуется определить пакет Python высшего уровня, который будет служить пространством имен для большой коллекции отдельно поддерживаемых подпакетов.

Нужно организовать код так же, как и в обычном пакете Python, но опустить файлы \verb|__init__.py| в каталогах, где компоненты будут объединяться. Пример \cite[\strbook{399}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
foo-package/
    spam/
        blah.py
        
bar-package/
    spam/
        grok.py
\end{lstlisting}

В этих каталогах имя \texttt{spam} используется в качестве общего пространства имен. Обратите внимание, что файл \verb|__init__.py| отсутствует в обоих каталогах.

Теперь, если добавить оба пакета \texttt{foo-package} и \texttt{bar-package} к пути поиска модулей Python и попробуете импортировать
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import sys
sys.path.extend(["foo-package", "bar-package"])
import spam.blah
import spam.grok
\end{lstlisting}

Для разных каталога пакетов слились вместе. Механизм, который здесь работает, известен под названием <<пакет пространства имен>>. По сути, пакет пространства имен -- это специальный пакет, разработанный для слияния различных каталогов с кодом под общим пространством имен.

Ключ к созданию пакета пространства имен -- отсутствие файлов \verb|__init__.py| в каталоге высшего уровня, который служит общим пространством имен. Вместо того чтобы выкинуть ошибку, интерпретатор начинает создавать список всех каталогов, которые содержит совпадающее имя пакета. Затем создается специальный модуль-пакет пространства имен, и в его переменной \verb|__path__| сохраняется доступная только для чтения копия списка каталогов.





\section{Некоторые приемы}

\subsection{Вычисления со словарями}

Рассмотрим словарь, который отображает тикеры на цены
\begin{lstlisting}[
style = ironpython,
numbers = none
]
d = {
    "ACME": 45.23,
    "AAPL": 612.78,
    "IBM": 205.55,
    "HPQ": 37.20,
    "FB": 10.75,
}
\end{lstlisting}

Чтобы найти наименьшую/наибольшую цены с тикером можно обратить ключи и значения, а затем воспользоваться функций \texttt{zip()}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
min(zip(d.values(), d.keys()))  # (10.75, "FB")
max(zip(d.values(), d.keys()))  # (612.78, "AAPL")
\end{lstlisting}

Важно иметь в виду, что функция \texttt{zip()} создает итератор, по которому можно пройти только один раз.

Использование функции \texttt{zip()} решает задачу путем <<обращения>> словаря в последовательность пар (value, key). 

Однако, вариант с функцией \texttt{zip()} требует большего времени, чем вариант на цикле
\begin{lstlisting}[
style = ironpython,
numbers = none
]
%%timeit -n 1_000_000
# 639 ns +/- 3.04 ns per loop (mean +/- std. dev. of 7 runs, 1,000,000 loops each)
min(zip(d.values(), d.values()))  

%%timeit -n 1_000_000
# 576 ns +/- 1.4 ns per loop (mean +/- std. dev. of 7 runs, 1,000,000 loops each)
def find_min_pair(d: t.Dict[str, float]) -> t.Tuple[float, str]:
    min_value = float("inf")
    for key, value in d.items():
        if value < min_value:
            min_value = d[key]
            min_key = key
    return (min_value, min_key)
\end{lstlisting} 

Пусть есть два словаря. Требуется выяснить, что у них общего
\begin{lstlisting}[
style = ironpython,
numbers = none
]
d1 = {"x": 1, "y": 2, "z": 3}
d2 = {"w": 10, "x": 11, "y": 2}

# Найти общие ключи
d1.keys() & d2.keys()

# Находим ключи, которые есть в d1, но которых нет в d2
d1.keys() - d2.keys()

# Находим общие пары (key, value)
d1.items() & d2.items()  # {("y", 2)}
\end{lstlisting}

Словарь -- это отображение множества ключей на мнгожество значений. Метод словаря \texttt{keys()} возвращает \emph{объект ключей словаря} \texttt{dict\_keys}. Малоизвестная особенность этих объектов заключается в том, что они поддерживают набор операций над \emph{множествами}: объединение, пересечение и разность. Так что, если требуется выполнить этот набор операций над ключами словаря, то можно использовать объект ключей словаря напрямую, без предварительного конвертирования во множество \cite[\strbook{35}]{beazley:python_cookbook-2019}, т.е.
\begin{lstlisting}[
style = ironpython,
numbers = none
]
d1.keys() & d2.keys()  # {"x", "y"}
# вместо
set(d1.keys()) & set(d2.keys())  # {"x", "y"}
# или
set(d1.keys()).intersection(set(d2.keys()))  # {"x", "y"}
\end{lstlisting}

Найти пересечение индексов двух серий можно было бы так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
ser1 = pd.Series(d1, name="ser1")
ser2 = pd.Series(d2, name="ser2")

pd.merge(
    ser1,
    ser2,
    left_index=True,
    right_index=True,
    how="inner"
).index.to_list()  # ["x", "y"]
\end{lstlisting}

\subsection{Удаление дубликатов из последовательности}

Вы хотите ислкючить дублирующиеся значения из последовательности, но при этом сохранить порядрк следования оставшихся элементов.

Если значения в последовательности являютеся хешируемыми, задача может быть легко решена с использованием множества и генератора
\begin{lstlisting}[
style = ironpython,
numbers = none
]
%%timeit -n 100_000
# 984 ns +/- 17.6 ns per loop (mean +/- std. dev. of 7 runs, 100,000 loops each)
def dedupe(items: t.Iterable[int]) -> t.Iterable[int]:
    seen: t.Set[int] = set()
    for item in items:
        if item not in seen:
            yield item  # отдать элемент
            seen.add(item)  # обновить множество
            
lst = [1, 5, 2, 1, 9, 1, 5, 10]
list(dedupe(lst))  # [1, 5, 2, 9, 10]
\end{lstlisting}

Или так
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
%%timeit -n 100_000
# 663 ns +/- 26.2 ns per loop (mean +/- std. dev. of 7 runs, 100,000 loops each)
def dedupe_list(items: t.Iterable[int]) -> t.Iterable[int]:
    seen: t.Iterable[int] = []
    for item in items:
        if item not in seen:
            seen.append(item)
    return seen
\end{lstlisting}

\subsection{Сортировка списка словарей по общему ключу}

У вас есть список словарей, и вы хотите отсортировать записи согласно одному или более полям. Сортировка структур этого типа легко выполняется с помощью функции \texttt{operator.itemgetter}. Именованный аргумент \texttt{key} должен быть \emph{вызываемым объектом} (т.е. объектом, в котором реализован метод \verb|__call__|). Функция \texttt{itemgetter()} создает такой вызываемый объект
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from operator import itergetter

records: t.Iterable[dict] = [
    {"fname": "Brian", "lname": "Jones", "uid": 1003},
    {"fname": "David", "lname": "Beazley", "uid": 1002},
    {"fname": "John", "lname": "Cleese", "uid": 1004},
]

# аргумент key ожидает получить вызываемый объект
sorted(records, key=itemgetter("fname"))
sorted(records, key=itergetter("uid"))
# то же, что и
sorted(records, key=lambda record: record["fname"])
sorted(records, key=lambda record: record["uid"])
\end{lstlisting}

Функция \texttt{itemgetter()} может принимать несколько полей
\begin{lstlisting}[
style = ironpython,
numbers = none
]
sorted(records, key=itemtegger("lname", "fname"))
\end{lstlisting}

Эту технику можно применять и к функциям \texttt{min}, \texttt{max}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# найти строку с наименьшим значением идентификационного номера
min(records, key=itemgetter("uid"))
\end{lstlisting}

\subsection{Отображение имен на последовательность элементов}

У вас есть код, который осуществляет доступ к элементам в списке или кортеже по позиции. Однако такой подход часто программу нечитабельной. 

\texttt{collections.namedtuple()} -- фабричный метод, который возвращает подкласс стандартного типа Python -- tuple. Метод возвращает класс, который может порождать экземпляры
\begin{lstlisting}[
style = ironpython,
numbers = none
]
Person = namedtuple("Person", ["name", "age", "job"])
leor = Person(name="Leor", age=36, job="DS")
\end{lstlisting}

Хотя экземпляр \texttt{namedtuple} выглядит так же, как и обычный экземпляр класса, он взаимозаменям с кортежем и поддерживает все обычные операции кортежей, такие как индексирование и распаковка
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
name, age, job = leor
\end{lstlisting}

Возможное использование именнованного кортежа -- замена словаря, который требует больше места для хранения. Так что, если создаете крупные структуры данных с использованием словарей, применение именованных кортежей будет более эффективным. Однако, именованные кортежи неизменяемы в отличие от словарей.

Если вам нужно изменить любой из атрибутов, это может быть сделано с помощью метода \verb|_replace()|, которым обладают экземпляры именованных кортежей.

Тонкость использования метода \verb|_replace()| заключается в том, что он может стать удобным способом наполнить значениями именованный кортеж, у которого есть опциональные или отсутствующие поля. Чтобы сделать это, создайте прототип кортежа, содержащий значения по умолчанию, а затем применяйте \verb|_replace()| для создания новых экземпляров с замененными значениями
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from collection import namedtuple

Stock = namedtuple("Stock", ["name", "shares", "price", "date", "time"])
stock_prototype = Stock("", 0, 0.0, None, None)

def dict_to_stock(s):
    return stock_prototype._replace(**s)
\end{lstlisting}

\section{Строки и текст}

\subsection{Разрезание строк различными разделителями}

Нужно разделить строку на поля, но разделители (и пробелы вокруг них) внтури строки разные
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import re
line = "asdf fjdk; afed, fjek,asdf,     foo"
re.split(r"[;,\s]\s*", line)
\end{lstlisting}





\section{Профилирование и замеры времени выполнения}

При проведении измерений производительности нужно помнить, что любые результаты будут приблизительными. Функция \texttt{time.perf\_counter()} предоставляет наиболее точный таймер из доступных. Однако она все-таки измеряет \emph{внешнее время}, и {\color{red}на результаты влияют различные факторы, такие как нагруженность компьютера}.

Если вы хотите получить время обработки, а не внешнее время, используйте \texttt{time.process\_time()} \cite[\strbook{574}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from functools import wraps

def timethis(func):
    @wraps(func)
    def wrapper(*args, **kwrags):
        start = time.process_time()  # <- NB
        r = func(*args, **kwargs)
        stop = time.process_time()  # <- NB
        print(f"{func.__module__}.{func.__name__} : {end - start}")
        return r
    return wrapper
    
@timethis
def countdown(n):
    while n > 0:
        n -= 1

countdown(100000)
\end{lstlisting}

Чтобы подсчитать время выполнения блока инструкций, можно определить менеджер контекста
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from contexlib import contexmanager

@contextmanager
def timeblock(label):
    start = time.process_time()
    try:
       yield
    finally:
        end = time.process_time()
        print(f"{label} : {end - start}")
        
with timeblock("counting"):
	n = 100000
	while n > 0:
	    n -= 1
	# counting: 1.55555
\end{lstlisting}

Запустить профилировщик для веб-приложения и перенаправить вывод профилировщика в файл
\begin{lstlisting}[
style = bash,
numbers = none
]
# В основном терминале
$ python -m cProfile flask_app.py > profile.log
 * Serving Flask app 'solverapi' (lazy loading)
* Environment: production
WARNING: This is a development server. Do not use it in a production deployment.
Use a production WSGI server instead.
* Debug mode: on
* Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
* Restarting with stat
* Debugger is active!
* Debugger PIN: 158-204-808

# В параллельном терминале
$ curl -H "Content-Type: application/json" -X POST --data "@file_name.json" "localhost:5000/api/solver/balance"
# После завершения расчета можно прервать сессию в основном терминале
$ vim profile.log
\end{lstlisting}

Граф цепочки выполнения программы можно построить следующим образом
\begin{lstlisting}[
style = bash,
numbers = none
]
$ pip install gprof2dot
$ python -m cProfile -o profile.pstat app.py
$ gprof2dot -f pstats profile.pstat | dot -Tpng -o output.png
\end{lstlisting}

Потребление памяти приложением можно оценить с помощью библиотеки \texttt{memory\_profiler} \url{https://pypi.org/project/memory-profiler/}. После установки библиотеки будет доступна утилита командной строки \texttt{mprof}.

Запустить приложение в режиме замера потребления памяти для основного (родительского) процесса и его дочерних процессов (если они существуют) можно следующим образом
\begin{lstlisting}[
style = bash,
numbers = none
]
$ mprof run --include-children --multiprocess script.py
\end{lstlisting}

После остановки приложения в рабочей директории будет создан dat-файл с результатами измерений потребления памяти. Построить график потребления можно так
\begin{lstlisting}[
style = bash,
numbers = none
]
# -s: угол наклона, по которому можно судить об утечке памяти
#  -t: заголовок графика
$ mprof plot -s -t "496.lp"
\end{lstlisting}

Перечень поддерживаемых флагов, связанных с конкретной подкомандой \texttt{mprof}, можно просмотреть так
\begin{lstlisting}[
style = bash,
numbers = none
]
$ mprof <subcommand> --help
...
\end{lstlisting}

Для измерения потребления памяти какой-то конкретной функции можно воспользоваться декоратором \texttt{@memory\_profiler.profile}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from memory_profiler import profile

@profile
def my_func():
    a = [1] * (10 ** 6)
    b = [2] * (2 * 10 ** 7)
    del b
    return a
\end{lstlisting}

Затем остается только запустить интерпретатор с флагом \verb|-m memory_profiler| и проанализировать ответ \texttt{memory\_profiler}.


\section{Итераторы и генераторы}

В большинстве случаев для прохода по итериуемому объекту используется цикл \texttt{for}. Однако иногда задачи требуют более точного контроля лежащего в основе механизма итераций. 

Следующий код иллюстрирует базовые механизмы того, что происходит во время итерирования
\begin{lstlisting}[
style = ironpython,
numbers = none
]
items = [1, 2, 3] # Итерируемый объект
# Получаем объект итератора
# Функция iter(items) вызывает метод итерируемого объекта items.__iter__()
it = iter(items) # Итератор
# Запускаем итератор
next(it) # Вызывается it.__next__() -> 1
next(it) # -> 2
next(it) # -> 3
next(it) # Возбуждается исключение StopIteration
\end{lstlisting}

Список \texttt{items} как \emph{итерируемый объект} имеет метод \verb|__iter__()|, который должен возвращать \emph{объект-итератора} (\texttt{it}). У объекта-итератора должен быть метод \verb|__next__()| для перебора элементов. Вот функция \texttt{next(it)} и вызывает метод \verb|__next__()| объекта-итератора для получения следующего элемента. Когда список исчерпывается, возбуждается исключение \texttt{StopIteration}.

\emph{Протокол итераций} Python требует, чтобы метод \verb|__iter__()| возвращал специальный объект-итератор, в котором реализован метод \verb|__next__()|, который выполняет итерацию \cite[\strbook{128}]{beazley:python_cookbook-2019}. Функция \texttt{iter()} просто вовзвращает внутренний итератор, вызывая \verb|s.__iter__()|.

\emph{Протокол итератора} Python требует \verb|__iter__()|, чтобы вернуть специальный \emph{объект итератора}, в котором реализован метод \verb|__next__()|, а исключение \texttt{StopIteration} используется для подачи сигнала о завершении \cite[\strbook{131}]{beazley:python_cookbook-2019}.

Когда поток управления покидает тело генераторной функции, возбуждается исключение \texttt{StopIteration}.

Метод \verb|__iter__()| \emph{итерируемого объекта} может быть реализован как обычная \emph{генераторная функция} \cite[\strbook{133}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
class linehistory:
    ...
    def __iter__(self):
        for lineno, line in enumerate(self.lines, 1):
            self.history.append((lineno, line))
            yield line
\end{lstlisting}

Для того чтобы пропустить первые несколько элементов по какому-то условию, можно воспользоваться функцией \texttt{itertools.dropwhile}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from itertools import dropwhile

def read_wo_header(file_name: str):
    with open(file_name, mode="r") as f:
        for line in dropwhile(lambda line: line.startswith("#"), f):
            print(line.rstrip())
\end{lstlisting}

Возвращаемый итератор отбрасывает первые элементы в последовательности до тех пор, пока предоставленная функция возвращает \texttt{True}.

Если нужно просто пропустить первые несколько строк файла (не по условию), то будет полезна функция \texttt{itertools.islice}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
with open(file_name, mode="r", encoding="utf-8") as f:
    for line in islice(f, 7, None):  # пропустить первые 7 строк файла
        if line.startswith("# rows".lower()):
            break
       ...
\end{lstlisting}

\section{Захват переменных в анонимных функциях}

Рассмотрим поведение следующей программы:
\begin{lstlisting}[
style = ironpython,
numbers = none
]
>>> x = 10
>>> a = lambda y: x + y
>>> x = 20
>>> b = lambda y: x + y
>>> a(10)  # 30
>>> b(10)  # 30
\end{lstlisting}

Проблема в том, что значение \texttt{x}, используемые lambda-выражением, является \emph{свободной переменной}, которая связывается во время \emph{выполнения}, а не во время \emph{определения} \cite[\strbook{233}]{beazley:python_cookbook-2019}. Так что значение \texttt{x} будет таким, каким ему случиться быть во время выполнения.

\remark{
\emph{Свободные переменные} связываются во время \emph{выполнения}, а не во время определения
}

Другими словами у замыканий позднее связывание. Замыкания -- это функции с расширенной областью видимости, которая включает все неглобальные переменные. То есть замыкания умеют запоминать привязки свободных переменных.

Например,
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
funcs = [
    lambda x: x + n
    for n in range(3)
]
for f in funcs:
    print(f(0))
# 2
# 2
# 2
\end{lstlisting}

\section{Передача дополнительного состояния с функциями обратного вызова}

\begin{lstlisting}[
style = ironpython,
numbers = none	
]
import typing as t

def apply_async(
    func: t.Callable,
    args: t.Tuple[t.Union[str, int],
    *,
    callback: t.Callable]
) -> t.NoReturn:
    result: t.Union[str, int] = func(*args)
    callback(result)
    
def add(x: int, y: int) -> int:
    return x + y
\end{lstlisting}

Для хранения состояния можно использовать \emph{замыкание} \cite[\strbook{238}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def make_handler():
    count = 0
    def handler(result: t.Union[str, int]) -> t.NoReturn:
        nonlocal count
        count += 1
        print(f"[{count}] Got: {result}")
    return handler
    
handler = make_handler()
apply_async(add, (2, 3), callback=handler)  # [1] Got: 5
apply_async(add, ("hello", "world"), callback=handler)  # [2] Got: hello world 
\end{lstlisting}

\section{Использование лениво вычисляемых свойств}

Вы хотите определить доступный только для чтения атрибут как свойство, которое вычисляется при доступе к нему. Однако после того, как доступ произойдет, значение должно кешироваться и не пересчитываться при следующих запросах.

Дескпритор -- класс, который реализует три ключевые операции доступа к атрибутам (получения, присваивания и удаления) в форме специальных методов \verb|__get__()|, \verb|__set__()| и \verb|__delete__()|.

Эффективный путь определинея ленивых атрибутов -- это использование \emph{класса-дескриптора} \cite[\strbook{271}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# дескрипторный класс
class lazyproperty:
    def __init__(self, f: t.Callable):
        self.f = f
        
    def __get__(self, instance, cls):
        if instance is None:
            # Если дескриптор вызывать через объект управляющего класса,
            # например как Circle.area, то instance=None и будет возвращена
            # ссылка на объект экземпляра дескриптора
            return self  
        else:
            value = self.f(instance)
            setattr(instance, self.f.__name__, value)
            return value
\end{lstlisting}

Чтобы использовать этот код, вы можете применить его в классе
\begin{lstlisting}[
style = ironpython,
numbers = none
]
class Circle:
    def __init__(self, radius: float):
        self.radius = radius
        
    @lazyproperty
    def area(self):
        print("Computing area")
        return math.pi * self.radius ** 2
    
    @lazyproperty
    def perimeter(self):
        print("Computing perimeter")
        return 2 * math.pi * self.radius
\end{lstlisting}

Вот пример использования
\begin{lstlisting}[
style = ironpython,
numbers = none
]
>>> c = Circle(radius=4.0)
>>> c.area
# Computing area
# 50.26...
>>> c.area  # 50.26...
\end{lstlisting}

Во многих случаях цель применения лениво вычисляемых атрибутов заключается в увеличении производительности. Например, вы можете избежать вычисления значений, если только они действительно где-то не нужны.

Когда дескриптор помещается в определение класса, его методы \verb|__get__()|, \verb|__set__()| и \verb|__delete__()| задействуются при доступе к атрибуту. Но если дескриптор определяет только метод \verb|__get__()|, то у него намного более слабое связывание, нежели обычно. В частности, метод \verb|__get__()| срабатывает, \emph{только если атрибут}, к которому осуществляется доступ, \emph{отсутствует в словаре экзмпляра} управляющего класса (в данном случае класса \texttt{Circle}) \cite[\strbook{272}]{beazley:python_cookbook-2019}.

Класс \texttt{lazyproperty} использует это так: он заставляет метод \verb|__get__()| сохранять вычисленное значение в экземпляре, используя то же имя, что и само свойство. С помощью этого значение сохраняется в словаре экземпляра и \underline{отключает будущие вычисления свойства}.

Возможный недостаток этого рецепта в том, что вычисленное значение становится изменяемым после создания. То есть значение, например, свойства \texttt{area} можн затереть.

Если это проблема, вы можете использовать немного менее эффективное решение \cite[\strbook{273}]{beazley:python_cookbook-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def lazyproperty(func):
    name = "_lazy_" + func.__name__
    @property
    def lazy(self):
        if hasattr(self, name):
            return getattr(self, name)
        else:
            value = func(self)
            setattr(self, name, value)
            return value
    return lazy
\end{lstlisting}

В этом случае операции присваивания недоступны
\begin{lstlisting}[
style = ironpython,
numbers = none
]
>>> c = Circle(4.0)
>>> c.area
Computing area
50.26...
>>> c.area
50.26...
>>> c.area = 25  # Поднимется исключение AttributeError
\end{lstlisting}

В этом случае все операции получения значения проводятся через функцию-геттер свойства. Это менее эффективно, чем простой поиск значения в словаре экземпляра.

Еще можно просто задекорировать свойство декоратором \texttt{lru\_cache}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from functools import lru_cache

class Circle:
    def __init__(self, radius: float):
        self.radius = radius
        
    @property
    @lru_cacha
    def area(self):
        print("Computing area")
        return math.pi * self.radius ** 2
        
    @property
    @lru_cache
    def perimeter(self):
        print("Computing perimeter")
        return 2 * math.pi * self.radius
        
        
>>> circle = Circle(4.0)
>>> circle.area
# Computing area
# 50.26...
>>> circle.area  # 50.26...
\end{lstlisting}


\section{Определение более одного конструктора в классе}

Вы пишите класс и хотите, чтобы пользователи могли создавать экземпляры не только лишь единственным способом, предоставленным \verb|__init__()|.

Чтобы определить класс с более чем одним конструктором, вы должны использовать метод класса
\begin{lstlisting}[
style = ironpython,
numbers = none
]
class Circle:
    def __init__(self, radius: float, color: str = "black"):
         """
         Первичный конструктор
         """
         self.radius = radius
         self.color = color
    
    @classmethod
    def make_default_circle(cls):
        """
        Альтернативный конструктор. Конструктор тривиального класса
        """
        return cls(radius=1.0, color="red")
    
    @property
    @lru_cache
    def area(self):
        print("Computing area")
        return math.pi * self.radius ** 2
    
    @property
    @lru_cache
    def perimeter(self):
        print("Computing perimeter")
        return 2 *  math.pi * self.radius
    
    def __repr__(self):
        return f"{type(self).__name__}(radius={self.radius}, color={self.color})"
    
    def get_params(self) -> dict:
        return {"raidus": self.radius, "color": self.color}
\end{lstlisting}

Одно из главных применений \emph{методов класса} -- это определение \emph{альтренативных конструкторов} \cite[\strbook{294}]{beazley:python_cookbook-2019}. 

При определении класса с множественными конструкторами необходимо делать функцию \verb|__init__()| максимально простой -- она должна просто присваивать атрибутам значения. А вот уже альтернативные конструкторы будут вызываться при необходимости выполнения продвинутых операций.

Если требуется вызывать методы по имени, то можно воспользоваться \texttt{operator.methodcaller()}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import operator

class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y
    
    def __repr__(self):
        return f"Point({self.x}, {self.y})"
        
    def distance(self, x, y):
        return math.hypot(self.x - x, self.y - y)

p = Point(2, 3)
operator.methodcaller("distance", 0, 0)(p)
\end{lstlisting}

Функция \texttt{methodcaller()} может быть полезна, например, в следующем случае
\begin{lstlisting}[
style = ironpython,
numbers = none
]
class Person:
    def __init__(self, name: str, job: str):
        self.name = name
        self.job = job
        
    def action_1(self):
        return "Action-1"
        
    def action_2(self):
        return "Action-2"
        
    def action_N(self):
        return "Action-N"
\end{lstlisting}

Вызвать действие теперь можно так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def make(*, obj, action: str):
    if hasattr(obj, action):
        return methodcaller(action)(obj)
    else:
        raise ValueError(f"Object '{type(obj).__name__}' has't action '{action}' ...")
        
leor = Person(name="Leor", job="ML")   
make(obj=leor, action="action_1")  # Action-1
make(obj=leor, action="action_2")  # Action-2
make(obj=leor, actin="action_10")  # ValueError
\end{lstlisting}

Без \texttt{methodcaller()} пришлось бы писать что-то вроде
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def bad_make(*, obj, action: str):
    if action == "action_1":
        obj.action_1()
    elif action == "action_2":
        obj.action_2()
    ...
\end{lstlisting}

\section{Класс загрузчик данных}

Иногда бывает удобно использовать свой загрузчик. Например, когда нужно работать с большими npz-файлами временных рядов
\begin{lstlisting}[
style = ironpython,
numbers = none
]
import pathlib2
import typing as t

class DataLoader:
    def __init__(self, data_dir):
        self.files = list(pathlib2.Path(data_dir).glob("*.npz"))
        
    def __getitem__(self, key):
        return self.read(self.files[key])
        
    def __iter__(self):
        yield from map(lambda file: self.read(file), self.files)
        
    def __len__():
        return len(self.files)
        
    def read(self, filepath):
        loader = np.load(filepath, allow_pickle=True)
        
        X = loader["X"]
        index = loader["index"]
        columns = loader["columns"]
        y = loader["y"]
        
data = DataLoader("./data")
\end{lstlisting}

\section{Параметрические декораторы}

Требуется создать функцию-декторатор, которая принимала бы аргументы
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from functools import wraps
import logging

# level, name и message -- это параметры декоратора
def logged(level, name=None, message=None):
    # это обычный декоратор, аргумент func которого ссылается на декорируемую функцию
    def decorate(func: t.Callable):
        logname = name if name else func.__module__
        log = logging.getLogger(logname)
        logmsg = message if message else func.__name__
        
        @wraps(func)
        # args и kwargs -- это аргументы задекорированной функции
        def wrapper(*args, **kwargs):
            log.log(level, logmsg)
            return func(*args, **kwargs)
        return wrapper
    return decorate
    
# Пример использования
@logged(logging.DEBUG)  # -> @decorate: add = deocrate(add) -> wrapper || add -> wrapper
def add(x, y):
    return x + y
    
@logged(logging.CRITICAL, "example")
def spam():
    print("Spam!")
\end{lstlisting}

Можно считать, что после объявления функции \texttt{add} вместо выражения \verb|@logged(logging.DEBUG)| стоит \verb|@decorate|, но при этом еще доступна переменная \verb|level| со значением \verb|@logging.DEBUG|, а также переменные \texttt{name} и \texttt{message} со значением \texttt{None}. Аргумент функции \texttt{decorate} получает ссылку на декорируемую функцию \texttt{add}. Затем локальные переменные \texttt{logname}, \texttt{log} и \texttt{logmsg} получают значения, после чего возвращается ссылка на вложенную функцию \texttt{wrapper}. Таким образом, при вызове функции \texttt{add} будет вызываться функция \texttt{wrapper}.

\section{Пользовательские исключения}

Можно не просто наследовать пользовательский класс исключения от класса \verb|Exception|, задавать сообщения по умолчанию и пр.
\begin{lstlisting}[
style = ironpython,
numbers = none
]
class PathToProblemError(Exception):
    """
    Incorrect path to problem
    """
    
    def __init__(
        self,
        message="Error! Incorrect path to problem: {}",
        *,
        incorrect_path_to_problem="",
    ):
        super().__init__(message.format(incorrect_path_to_problem))
\end{lstlisting}

\section{Определение декоратора, принимающего необязательный аргумент}

Вы хотели бы написать один декоратор, который можно было бы использовать и без аргументов -- \verb|@decorator|, и с необязательными аргументами \verb|@decorator(x, y, z)| \cite[\strbook{339}]{beazley:python_cookbook-2019}.

\begin{lstlisting}[
style = ironpython,
numbers = none
]
from functools import wraps, partial
import logging

def logged(func=None, *, level=logging.DEBUG, name=None, message=None):
    if func is None:
        return partial(logged, level=level, name=name, message=message)
        
    logname = name if name else func.__module__
    log = logging.getLogger(logname)
    logmsg = message if message else func.__name__
    
    @wraps(func)
    def wrapper(*args, **kwargs):
        log.log(level, logmsg)
        return func(*args, **kwargs)
    return wrapper
    
# Пример использования
@logged
def add(x, y):
    return x + y
    
@logged(level=logging.CRITICAL, name="example")
def spam():
    print("Spam")
\end{lstlisting}

Этот рецепт просто заставляет декоратор одинаково работать и с дополнительными скобками, и без.

Чтобы понять принцип работы кода, вы должны четко понимать то, как декораторы применяются к фукнциям, а также условия их вызова. Для простого декоратора, такого как этот
\begin{lstlisting}[
style = ironpython,
numbers = none
]
@logged  # logged(func=add, ...)
def add(x, y):
    return x + y
\end{lstlisting}
последовательность вызова будет такой
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def add(x, y):
    return x + y
    
add = logged(add)
\end{lstlisting}

В этом случае обертываемая функция просто передается в \texttt{logged} первым аргументом. Поэтому в решении первый аргумент \texttt{logged()} -- это обертываемая функция. Все остальные аргументы должны иметь значения по умолчанию.

Для декоратора, принимающего аргументы, такого как этот
\begin{lstlisting}[
style = ironpython,
numbers = none
]
@logged(level=logging.CRITICAL, name="example")  # logged(func=None, ...)
def spam():
    print("Spam")
\end{lstlisting}
последовательность вызова будет такой
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def spam():
    print("Spam")

spam = logged(level=logging.CRITICAL, name="example")(spam)
\end{lstlisting}

При первичном вызове \verb|logged()| обертываемая функция не передается. Так что в декораторе она должна быть необязательной. Это, в свою очередь, заставляет другие аргументы быть именованными. Более того, когда аргументы переданы, декоратор должен вернуть функцию, которая принимает функцию и оборачивает ее. Чтобы сделать это, в решении используется хитрый трюк с \texttt{functools.partial}. Если точнее, он просто возвращает частично примененную версию себя, где все аргументы зафиксированы, за исключением обертываемой функции.

Таким образом, при повторном вызове функции \texttt{logged} через \texttt{partial} вызов будет выглядеть следующим образом
\begin{lstlisting}[
style = ironpython,
numbers = none
]
spam = logged(func=spam, level=logging.CRITICAL, name="example", message=None)
\end{lstlisting}

Одна из особенностей декораторов в том, что они \underline{применяются только один раз}, во время \emph{определения} функции \cite[\strbook{342}]{beazley:python_cookbook-2019}

\section{Параллельное программирование}

Библиотека \texttt{concurent.futures} предоставляет класс \texttt{ProcessPoolExecutor}, который может быть использован для выполнения тяжелых вычислительных задач в \emph{отдельно запущенных экземплярах интерпретатора Python} \cite[\strbook{498}]{beazley:python_cookbook-2019}.

<<Под капотом>> \texttt{ProcessPoolExecutor} создает $ N $ независимо работающих интерпретаторов Python, где $ N $ -- это количество доступных обнаруженных в системе CPU. Пул работает до тех пор, пока не будет выполнена последняя инструкция в блоке \texttt{with}, после чего пул процессов завершается. Однако программа будет ждать, пока вся отправленная работа не будет сделана.

Чтобы получить результат от экземпляра Future, нужно вызвать метод \texttt{result()}. Это вызовет \emph{блокировку} на время, пока результат не посчитается и не будет возвращен пулом.

Несколько вопросов, связанных с пулами процессов:
\begin{itemize}
	\item Этот прием распараллеливания работает только для задач, которые легко раскладываются на независимые части,
	
	\item Работа должна отправляться в форме простых функций,
	
	\item Аргументы функций и возвращаемые значения должны быть совместимы с pickle. Работа выполняется в отдельном интерпретаторе при использовании межпроцессной коммуникации. Так что данные, которыми обмениваются интерпретаторы, должны \emph{сериализоваться},
	
	\item Пулы процессов в Unix создаются с помощью системного вызова \texttt{fork()}. Он создает клон интерпретатора Python, включая все состояние программы на момент копирования. В Windows запускается независимая копия интерпретатора, которая не клонирует состояние,
	
	\item Нужно с великой осторожностью объединять пулы процессов с программами, которые используют потоки.
\end{itemize}

\subsection{Пример использования пула потоков}

Требуется для каждой переменной в MILP-задаче описать контекст переменной через типы переменных, которые встречаются в тех ограничениях, в которые входит рассматриваемая переменная. Для примера пусть переменная входит в 3 ограничения. В первом ограничении кроме рассматриваемой переменной есть еще две: одна, скажем, вещественная, а другая целочисиленная. Во втором ограничении кроме рассматриваемой переменной есть еще 3 вещественные. А в третьем ограничении кроме рассматриваемой есть еще одна бинарная. Тогда для рассматриваемой переменной мы должны получить такой контекст: \verb|"{CONTINUOUS": 4, "BINARY": 1, "INTEGER": 1}|. Затем полученные контексты собираются в список словарей. На этом списке требуется построить кадр данных. В данном случае это можно сделать так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
pd.DataFrame.from_dict(ChainMap(*results), orient="index")  # ОЧЕНЬ МЕДЛЕННО!
\end{lstlisting}

Построение кадра данных на 26 000 контекстов занимает около 2-х минут. Оданко, если список \verb|results| разбить на пакеты, для каждого пакета построить кадр данных, собрать в список, а затем склеить с помощью \verb|pd.concat()|, то время построения снижается до 6 секунд
\begin{lstlisting}[
style = ironpython,
numbers = none
]
dfs = []
for batch_idx in range(math.ceil(len(results) / batch_size)):
    _part = results[batch_idx * batch_size : (batch_idx + 1) * batch_size]
    dfs.append(pd.DataFrame.from_dict(ChainMap(*_part), orient="index"))
    
_features = pd.concat(dfs, axis=0)
\end{lstlisting}

Каждое обращение к \verb|executor.submit| \emph{планирует выполнение} одного вызываемого объекта и возвращает экзмепляр \verb|Future|. Первый аргумент -- сам вызываемый объект, остальные -- передаваемые ему аргументы. 

Функция \verb|as_completed()| возвращает итератор, который отдает будущие объекты по мере их завершения: \verb|as_completed()| возвращает \emph{только уже завершенные} будущие объекты.

\begin{lstlisting}[
style = ironpython,
numbers = none
]
def _get_var_context_types(
	self,
	conss: t.Iterable[t.Tuple[str, dict]],
	var_name: str,
) -> dict:
	"""
	Gets var types in context current var. For example,
	"y_var_1" -> {"CONTINUOUS": 8, "INTEGER": 4, "BINARY": 0}
	"""
	cons_name: str
	cons: dict
	_var_types: t.List[str] = []
	var_context_types: t.Dict[str, int]
	
	for cons_name, cons in conss:
		if var_name in cons:
		_var_types.extend(
			[
				self._var_name_to_var_type.get(_var_name)
				for _var_name in cons.keys()
				if var_name != _var_name
			]
		)
	
	if not _var_types:
		var_context_types = {VAR_TYPE_CONTINUOUS: 0, VAR_TYPE_BINARY: 0, VAR_TYPE_INTEGER: 0}
	else:
		var_context_types = Counter(_var_types)
	
		not_represented_var_types: t.Set[str] = {
			VAR_TYPE_CONTINUOUS,
			VAR_TYPE_BINARY,
			VAR_TYPE_INTEGER,
		}.difference(set(_var_types))
	
		if not_represented_var_types:
			for var_type in not_represented_var_types:
				var_context_types.update({var_type: 0})
	
	return {var_name: var_context_types}

def build_var_context_types(
	self,
	var_names: t.List[str],
	conss: t.Iterable[t.Tuple[str, dict]],
	batch_size: int = 2_000,
	max_n_threads: int = 100,
) -> pd.DataFrame:
	"""
	Builds features for var context types in parallel mode
	"""
	with ThreadPoolExecutor(max_workers=max_n_threads) as executor:
		to_do: t.List[Future] = []
	
		for var_name in tqdm(var_names):
			future: Future = executor.submit(self._get_var_context_types, conss, var_name)
			to_do.append(future)
	
		results: t.List[dict] = []
		for future in as_completed(to_do):
			result = future.result()
			results.append(result)
	
	dfs: t.List[pd.DataFrame] = []
	for batch_idx in tqdm(range(math.ceil(len(results) / batch_size))):
		_part = results[batch_idx * batch_size : (batch_idx + 1) * batch_size]
		dfs.append(pd.DataFrame.from_dict(ChainMap(*_part), orient="index"))
	
	_features = pd.concat(dfs, axis=0)
	_features.columns = [f"{col_name.lower()}_type_context" for col_name in _features.columns]
	
	return _features
\end{lstlisting}

\subsection{Процессы, потоки и GIL в Python}

Выдержка из книги Л. Рамальо \cite[\strbook{650}]{ramalho:python-2022}:
\begin{itemize}
	\item Каждый \emph{экземпляр интрепретатора Python} является \emph{процессом}. Дополнительные процессы Python можно запускать с помощью библиотек \texttt{multiprocessing} или \texttt{concurrent.futures}. 
	
	\item Интерпретатор Python использует единственный поток, в котором выполняется и пользовательская программа, и сборщик мусора. Для запуска дополнительных потоков предназначены библиотеки \texttt{threading} и \texttt{concurrent.futures}.
	
	\item Только один поток может выполнять Python-код, и от числа процессорных ядер это не зависит.
	
	\item Любая стандартная библиотечная функция Python, делающая системный вызов, освобождает GIL. Сюда относятся все функции, выполняющие дисковый ввод-вывод, сетеовой ввод-вывод, а также \texttt{time.sleep()}. Многие счетные функции в библиотеках numpy/scipy, а также функции сжатия и распаковки из модулей \texttt{zlib} и \texttt{bz2} также освобождают GIL.
	
	\item Влияние GIL на сетевое программирование с помощью потоков Python сравнительно невелико, потому что функции ввода-вывода освобождают GIL, а чтение или запись в сеть всегда подразумевает высокую задержку по сравнению с чтением-записью в память. Следовательно, каждый отдельный поток все равно тратит много времени на ожидание, так что их выполнение можно чередовать без заметного снижения общей пропускной способности.
	
	\item Состязание за GIL замедляет работу счетных потоков в Python. В таких случаях последовательный однопоточный код проще и быстрее.
	
	\item Для выполнения счетного Python-кода на нескольких ядрах нужно использовать несколько процессов Python.
\end{itemize}

Деталь реализации CPython. В CPython, из-за глобальной блокировки интерпретатора, в каждый момент времени Python-код может выполняться только одним потоком (хотя некоторые высокопроизводительные библиотеки умеют обходить это ограничение). Если вы хотите, чтобы приложение более эффективно использовало вычислительные ресурсы многоядерных машин, то пользуйтесь модулем \texttt{multiprocessing} или классом \texttt{concurrent.futures.ProcessPoolExecutor}. Однако многопоточное выполнение все же является вполнен пригодной моделью, если требуется одновременно выполнять несколько задач с большим объемом ввода-вывода \cite[\strbook{652}]{ramalho:python-2022}.

По умолчанию \emph{сопрограммы} вместе с \emph{управляющим циклом событий}, который предоставляется каркасом асинхронного программирования, работают в \emph{одном потоке}, поэтому GIL не оказывает на них никакого влияния. Можно использовать несколько потоков в асинхронной программе, но рекомендуется, чтобы и цикл событий, и все сопрограммы исполнялись в одном потоке, а дополнительные потоки выделялись для специальных задач.



\subsection{Глобальная блокировка интерпретатора}

Интерпретатор защищен так называемой глобальной блокировкой интерпретатора (GIL), которая позволяет \emph{только одному потоку} Python выполняться в любой конкретный момент времени \cite[\strbook{503}]{beazley:python_cookbook-2019}.

Наиболее заметный эффект GIL в том, что многопоточные программы Python не могут полностью воспользоваться преимуществами многоядерных процессоров (тяжелые вычислительные задачи, использующие больше одного потока, работают только на одном ядре процессора) \cite[\strbook{503}]{beazley:python_cookbook-2019}.

{\color{blue}GIL влияет только на программы, сильно нагружающие CPU} (то есть те, в которых вычисления доминируют). Если ваша программа в основном занимается вводом-выводом, что типично для сетевых коммуникаций, потоки часто являются разумным выбором, потому что они проводят большую часть времени в ожидании.

\section{Проверка сущестования путей в \texttt{dataclass}}

Для того чтобы при чтении конфигурационного файла проекта, выполнялась проверка существования путей, следует задекорировать класс-схему следующим образом \url{https://harrisonmorgan.dev/2020/04/27/advanced-python-data-classes-custom-tools/}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
def validated_dataclass(cls):
	"""
	Class decorator for validating fields
	"""
	cls = dataclass(cls)

	def _set_attribute(self, attr, value):
		for field in fields(self):
			if field.name == attr and "validator" in field.metadata:
				value = field.metadata["validator"](value)
				break

		object.__setattr__(self, attr, value)
		cls.__setattr__ = _set_attribute

		return cls


@validated_dataclass
class Paths:
	path_to_test_lp_file: str = field(metadata={"validator": check_existence_path})
	path_to_set_file: str = field(metadata={"validator": check_existence_path})
	path_to_output_dir: str = field(metadata={"validator": check_existence_path})

def check_existence_path(path: str):
	path = pathlib2.Path(path)
	if not path.exists():
		raise FileNotFoundError(f"Path {path} not found ...")
	
	return path
\end{lstlisting}

\section{Приемы работы с библиотекой SPyQL}

SPyQL \url{https://github.com/dcmoura/spyql}  -- это утилита командной строки, позволяющая писать SQL-подобные запросы к csv-, json-файлам, с использованием выразительных средств Python.

Прочитать csv-файл и вывести первые две записи в json-формате
\begin{lstlisting}[
style = bash,
numbers = none
]
$ spyql "SELECT * FROM csv LIMIT 2 TO json(indent=2)" < features_a78cbead_bin.csv
{
	"var": "alpha_tu_0_1_12_1",
	"scenario": "a78cbead_bin",
	"varBinaryOriginal": 1,
	"varTypeTrans": 0,
	"varStatus": 1,
	"varMayRoundUp": 0,
	"varMayRoundDown": 0,
	"varMayIsActive": 1,
	"varIsDeletable": 0,
	"varIsRemovable": 0,
	"varObj": 0.0,
	"varPseudoSol": -0.0,
	"NLocksDown": 1,
	"NLocksUp": 1,
	"IsTransformed": 1,
	"multaggrConstant": 0,
	"varAggrScalar": 0,
	"varAggrConstant": 0,
	"varMultaggrNVars": 0,
	"varBestBound": -0.0,
	"varWorstBound": 1.0,
	"varBranchFactor": 1,
	"varBranchPriority": 0,
	"varBranchDirection": 3,
	"varNImpls0": 0,
	"varNImpls1": 0,
	"varGetNCliques0": 0,
	"varGetNCliques1": 0,
	"varConflictScore": 1e-12,
	"varAvgInferenceScore": 87.0136,
	"relaxSolVal": 0.458516,
	"varImplRedcost0": 0.0,
	"varImplRedcost1": 0.0,
	"varPseudocostScore": 0.248279,
	"equalToLb": 0,
	"equalToUb": 0,
	"target": 1
}
...
\end{lstlisting}

Прочитать csv-файл, сгруппировать по полю \texttt{varStatus}, а затем из результата выбрать строки, в которых \texttt{varStatus > 2}
\begin{lstlisting}[
style = bash,
numbers = none
]
$ cat features_a78cbead_bin.csv \
    | spyql "SELECT varStatus AS status, count_agg(*) AS count FROM csv GROUP BY 1 TO spy" \
    | spyql "SELECT * FROM spy WHERE status > 2 ORDER BY 2 DESC TO pretty"
  
  status    count
 --------  -------
     3     8361
     4      552
\end{lstlisting}


\section{Приемы работы с библиотекой Pandas}

\subsection{Общие замечания}

Как отмечается в библиотеке \verb*|pandarallel| \url{https://nalepae.github.io/pandarallel/} основной недостаток библиотеки \verb|pandas| заключается в том, что она может \emph{\color{red}утилизировать только одно ядро процессора}, даже если доступно несколько ядер.

Библиотека \verb|pandarallel| может использовать все доступные ядра процессора, однако ей требуется в два раза больше памяти, чем \verb|pandas|. Не рекомендуется использовать \verb|pandarallel|, если \verb|pandas|-данные не помещаются в память. В этом случае лучше подойдет Spark.

Библиотека Spark позволяет работать с данными, которые \emph{значительно превышают доступную память} (Handle data much bigger than your memory) и может распределять вычисления по нескольким узлам кластера.

\subsection{Советы по оптимизации вычислений}

В ситуации, когда необходимо итерирование, более быстрым способом итерирования строк будет использование метода \texttt{.iterrows()}. Метод \texttt{.iterrows()} оптимизирован для работы с кадрами данных, и хотя это наименее эффективный способ большинства страндартных функций, он дает значительное улучшение, по сравнению с базовым итерированием \cite[\strbook{328}]{heydt:pandas-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
haversine_series = []
for index, row in df.iterrows():
    haversine_series.append(haversine(...))
df["distance"] = haversin_series
\end{lstlisting}

Однако метод \verb|.iterrows()| не сохраняет типы по строкам. Если требуется сохранять типы атрибутов строки, то лучше воспользоваться методом \verb|.itertuples()|, который поддреживает итерирование по строкам в виде именных кортежей. Кроме того часто \verb|.itertuples()| оказывается быстрее \verb|.iterrows()|.

Более эффктивным способом является использование метода \texttt{.apply()}, который применяет функцию вдоль определеной оси (вдоль строк или вдоль столбцов) кадра данных.

Хотя метод \texttt{.apply()} также по своей сути \emph{\color{red}перебирает строки} (!), он делает это намного эффективнее, чем метод \texttt{.iterrows()}, используя ряд внутренних оптимизаций, например, применяя итераторы, написанные на Cython \cite[\strbook{328}]{heydt:pandas-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df["distance"] = df.apply(lambda row: haversine(..., ..., row["latitude"], row["longitude"]), axis=1)
\end{lstlisting}

Но гораздо эффективнее задействовать \emph{векторизацию} и передать не скаляры, а столбцы
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df["distance"] = haversine(..., ..., df["latitude"], df["longitude"])
\end{lstlisting}

Если скорость имеет наивысший приоритет, можно вместо серий использовать numpy-массивы. Как и pandas, numpy работает с массивами. однако она освобождена от дополнительных вычислительных затрат, связанных с операциями в pandas, такими как индексирование, проверка типов данных и т.д. В результате операции над массивами numpy могут выполняться значительно быстрее, чем операции над объектами \texttt{Series}.

Массивы numpy можно использовать вместо объектов \texttt{Series}, когда дополнительная функциональность, предлагаемая объектами \texttt{Series}, не является критичной. Например, векторизованная реализация функции \texttt{haversine} фактически не использует индексы в сериях \texttt{langitude} и \texttt{latitude}, и поэтому отсутствие этих индексов не приведет к нарушению работы функции
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df["distance"] = haversine(..., ..., df["latitude"].values, df["longitude"].values)
\end{lstlisting}

Оптимизацию числовых столбцов можно выполнить с помощью \emph{понижающего преобразования}, используя функцию \texttt{pd.to\_numeric}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df.select_dtypes(np.dtype("int64")).apply(
    pd.to_numeric,  # функция, которая применяется к int-столбцам
    downcast="unsigned"  # аргумент функции pd.to_numeric
)
\end{lstlisting}

В значительной степени снижение потребления памяти будет зависеть от оптимизации столбцов типа \texttt{object}. Тип \texttt{object} представляет значения, использующие питоновские объекты-строки, отчасти это обусловлено отсутствием поддержки пропущенных строковых значений в numpy. Python не предполагает точной настройки способа хранения значений в памяти. Это ограничение приводит к тому, что строки хранятся фрагментированно, это потребляет больше памяти и замедляет доступ. Каждый элемент в столбце типа \texttt{object} является, по сути, указателем, который содержит <<адрес>> фактического значения в памяти \cite[\strbook{347}]{heydt:pandas-2019}.

Преобразовать столбец типа \texttt{object} в столбец типа \texttt{category} можно так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df["object_col_name"].astype("category")
\end{lstlisting}

Хотя каждый указатель занимает 1 байт памяти, каждое фактическое строковое значение использует такой объем памяти, какой строка использовала бы, если бы отдельно хранилась в Python.

Тип \texttt{category} под капотом для представления строковых значений в столбце вместо исходных использует целочисленные значения. Для этого создается отдельный словарь, в котором исходным значениям сопоставлены целочисленные значения. Это сопоставление будет полезно для столбцов с небольшим числом уникальных значений.

Рекомендуется придерживаться типа \texttt{category} при работе с такими столбцами \texttt{object}, в которых менее 50\% значений являются уникальными. Если все значения в столбце являются уникальными, тип \texttt{category} будет использовать б\emph{о}льший объем памяти. Это обусловлено тем, что в столбце, помимо целочисленных кодов, представляющих категории, храняться все исходные строковые значения.


\subsection{Рецепты}

\subsubsection{Приемы работы с кадрами данных}

Построить кадр данных заполненный \verb|NaN|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df = pd.DataFrame(np.nan, index=range(10), columns=["col1", "col2", "col3"])
\end{lstlisting}

Ремарка: с помощью \verb|scipy.sparse.scr_matrix| можно создавать огромные разреженные матрицы
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from scipy.sparse import csr_matrix

mtx = csr_matrix((300_000, 30_000), dtype=np.int8)
\end{lstlisting} 

Еще для создания разреженных матриц можно воспользоваться функцией \verb|scipy.sparse.lil_matrix|, которая создает разреженные матрицы инкрементно (поэтапно) и представляет список списков разрежнных матриц.

Например, индексы столбцов в строке номер 100, элементы которых равны единице можно получить так
\begin{lstlisting}[
style = ironpython,
numbers = none
]
from scipy.sparse import lil_matrix

mtx = lil_matrix((300_000, 30_000), dtype=np.int8)
mtx[100:300, 200:250] = 1
(mtx[100, :] == 1).indices
\end{lstlisting}

Вывести точную информацию об использовании памяти
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
df.info(memory_usage="deep")
"""
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1000 entries, 0 to 999
Data columns (total 3 columns):
#   Column  Non-Null Count  Dtype
---  ------  --------------  -----
0   key1    1000 non-null   float64
1   key2    1000 non-null   int64
2   color   1000 non-null   object
dtypes: float64(1), int64(1), object(1)
memory usage: 75.3 KB
"""
\end{lstlisting}

Посмотреть какие строки значений (а не индексы) кадра данных попали в ассоциированные группы
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df.groupby("color").groups.keys()
\end{lstlisting}

Заполнить пропущенные значения групповым средним по столбцу. Метод \verb|apply| в случае сгруппированных объектов применяет переданную функцию (в данном случае анонимную) к каждой группе, а внутри группы операции применяются вдоль указанных осей
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# Нужно отобрать поля, к которым будет применяться функция
df["year"] = df.groupby("color")["year"].apply(  # .loc[:, "year"] НЕ РАБОТАЕТ!
    lambda group: group.fillna(group.mean())
)
\end{lstlisting}

Для того чтобы метод \verb|apply| корректно работал на объекте групп нужно указать с какими полями мы будем работать
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# Указываем поля "year" и "mark"
df.groupby("model_car_id")[["year", "mark"]].appply(lambda gr: gr.fillna(gr.mean()))
# или
df.groupby("model_car_id")[["year", "mark"]].transform(lambda gr: gr.fillna(gr.mean()))
\end{lstlisting}

Метод \verb|transform| объекта GroupBy применяет указанную функцию \emph{к каждой группе}, а затем помещает результаты в нужные места \cite[\strbook{291}]{mckinney:pandas-2015}.

В самом простом случае метод \texttt{transform} применяет переданную функцию вдоль указанного направления и для каждого элемента возвращает результат преобразования, а в случае если метод \verb|transform| вызывается на GroupBy-объекте, то метод применяет указанную функцию для каждой группы и <<заменяет>> каждый элемент своей группы групповым аггрегатом или результатом преобразования (причем для каждого столбца вычисляется свой аггрегат)
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# каждый элемент групп будет заменен количеством элементов в группе
df.groupby("color")["elems"].transform(len)
\end{lstlisting}

Другими словами, метод \verb|transform| на сгруппированном объекте в том подкадре данных, который возвращается методом, каждый элемент группы <<заменяет>> групповым аггрегатом (или результатом преобразования), а метод \verb*|apply| просто применяет указанную функцию \emph{к каждой группе} \cite[\strbook{292}]{mckinney:pandas-2015} и склеивает результаты, т.е. возвращает результат для каждой группы
\begin{lstlisting}[
style = ironpython,
numbers = none
]
$ df.groupby("color")[["a", "e"]].transform(lambda gr: gr.mean())
# В столбце 'a' для элементов, попавших в группу, среднее было 49.377..., поэтому эти элементы заменены на соответсвующее групповое среднее
              a          e
0     49.377209  49.611246
1     49.950178  49.839233
2     49.730188  48.043373
3     49.730188  48.043373
4     49.950178  49.839233
...         ...        ...
9995  49.377209  49.611246
9996  49.377209  49.611246
9997  49.377209  49.611246
9998  49.950178  49.839233
9999  49.950178  49.839233
$ df.groupby("color")[["a", "e"]].apply(lambda gr: gr.mean())
               a          e
color
blue   49.730188  48.043373
green  49.950178  49.839233
red    49.377209  49.611246
\end{lstlisting}

Получается, что ключевое отличие метода \verb|transform| от метода \verb|apply| на GroupBy-объектах заключается в том, что \verb|transform| \emph{преобразует элементы группы}, а метод \verb|apply| просто разбивает кадр данных на группы, применяет указанную функцию к каждой группе, а затем пытается склеить результаты, то есть это что-то вроде концепции map-reduce.

Например, если требуется создать новый столбец, элементы которого помечаются меткой \verb|"old"|, если элемент меньше группового среднего и -- меткой \verb|"new"|, если элемент больше группового среднего, то можно решить эту задачу с помощью метода \verb|transform|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df["avg_a"] = df.groupby("color")["a"].transform(np.mean)
df["age"] = np.where(df["a"] < df["avg_a"], "old", "new")
\end{lstlisting}

То есть еще раз, метод \verb|transform| применяет указанную функцию (\verb|np.mean|) к каждой группе, а затем возвращает подкадр данных, в котором каждый элемент заменяется групповым аггрегатом.

Найти среднее и страндартное отклонение по группам для вещественных столбцов кадра данных
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df.groupby("label")[
    df.select_dtypes(np.dtype("float64")).columns
].agg([np.mean, np.std]).stack()
\end{lstlisting}

При проведении разведочного анализа данных лучше всего сначала загрузить данные и исследовать их с помощью запросов/логического отбора. Затем создайте индекс, если ваши данные поддерживают его или если вам требуется повышенная производительность \cite[\strbook{115}]{heydt:pandas-2019}. Операции поиска с использованием индекса обычно выполняются быстрее. В силу лучшей производительности выполнение поиска по индексу (в тех случаях, когда это возможно) обычно является оптимальным решением. Недостаток использования индекса заключается в том, что потребуется время на его создание, кроме того, он занимает больше памяти.

Выполнить слияние кадров данных можно с помощью функции \texttt{pd.merge} или метода \texttt{.merge}. По умолчанию слияние выполняется по \emph{общим меткам столбцов}, однако сливать кадры данных можно и \emph{по строкам с общими индексами} \cite[\strbook{230}]{heydt:pandas-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# Слияние по строкам
# Нужно задать оба параметра!
left.merge(right, left_index=True, right_index=True)
\end{lstlisting}

Кроме того, библиотека pandas предлагает метод \texttt{.join()}, который можно использовать для выполнения соединения с помощью \emph{индексных меток} двух объектов \texttt{DataFrame} (вместо значений столбцов) \cite[\strbook{232}]{heydt:pandas-2019}
\begin{lstlisting}[
style = ironpython,
numbers = none
]
# Слияние по строкам
# Здесь предполагается, что кадры данных имеют
# дублирующиеся имена столбцов, поэтому мы задаем lsuffix и rsuffix
left.join(right, lsuffix="_left", rsuffix="_right")
\end{lstlisting}

\remark{
Метод \texttt{.join()} по умолчанию используется \emph{внешнее соединение}, в отличие от метода \texttt{.merge()}, в котором по умолчанию применяется \emph{внутренее соединение}.
}

\emph{Состыковка} (stack) помещает уровень индекса столбцов в новый уровень индекса строк
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df = pd.DataFrame({
    "a": [1, 2],
    "b": [100, 200]
})
"""
     a    b
one  1  100
two  2  200
"""
df.stack()
"""
one  a      1
	   b    100
two  a      2
 	   b    200
"""
df.loc[("one", "b")]  # 100
\end{lstlisting}

Состыковку удобно применять к результатам аггрегации на группах
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
df.groupby("color")[["key1", "key4"]].agg([np.mean, np.std])
"""
           key1            key4
           mean       std  mean        std
color
blue   0.904027  0.508690  73.5  21.920310
green -0.493756  1.025554  65.0   9.899495
red   -0.399363       NaN  55.0        NaN
"""
# Состыковка
res = df.groupby("color")[["key1", "key4"]].agg([np.mean, np.std]).stack()
"""
                key1       key4
color
blue  mean  0.904027  73.500000
      std   0.508690  21.920310
green mean -0.493756  65.000000
      std   1.025554   9.899495
red   mean -0.399363  55.000000
"""
res.loc[("blue", "mean")]
"""
key1     0.904027
key4    73.500000
Name: (blue, mean), dtype: float64
"""
\end{lstlisting}

При построении агрегатов со сложным именем можно воспользоваться псевдонимами
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df.groupby("color")[["key1", "key2"]].agg([("MEAN", np.nanmean), ("STD", np.nanstd)]).stack()
"""
                key1      key2
color
blue  MEAN  0.544329  0.731969
green MEAN  0.231420  1.272040
       STD        NaN  1.255945
red   MEAN -0.399363  0.483054
"""
\end{lstlisting}

\emph{Расстыковка} (unstack) помещает самый внутренний уровень индекса строк в новый уровень индекса столбцов.

\emph{Расплавление} -- это тип организации данных, который часто называют преобразованием объекта DataFrame из <<широкого>> формата в <<длинный>> формат.
\begin{lstlisting}[
style = ironpython,
numbers = none
]
data = pd.DataFrame({
    "Name": ["Mike", "Mikal"],
    "Height": [6.1, 6.0],
    "Weight": [220, 185],
})
data
"""
     Name  Heigth  Weight
0    Mike     6.1     220
1  Mikael     6.0     185
"""
\end{lstlisting}

Расплавляем кадр данных
\begin{lstlisting}[
style = ironpython,
numbers = none
]
pd.melt(
    data,
    id_vars=["Name"],
    value_vars=["Height", "Weight"]
)
"""
     Name variable  value
0    Mike   Heigth    6.1
1  Mikael   Heigth    6.0
2    Mike   Weight  220.0
3  Mikael   Weight  185.0
"""
\end{lstlisting}

Получить данные по группе
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df.groupby("color").get_group("blue")
\end{lstlisting}

Отфильтровать группы по условию. Если функция возвращает \texttt{True}, то группа включается в результат
\begin{lstlisting}[
style = ironpython,
numbers = none
]
df.groupby("color").filter(lambda group: group.col_name.count() > 1)
\end{lstlisting}

\subsubsection{Изменение настроек отдельной линии графика на базе кадра данных}
Чтобы изменить, например, толщину линии для какого-то заданного столбца кадра данных нужно получить доступ к перечню линий \verb|ax.get_lines()|
\begin{lstlisting}[
style = ironpython,
numbers = none
]
fig, ax = plt.subplots(figsize=(15, 5))

df.plot(ax=ax, marker="o", style=["b--", "k-", "r-"])

for line in ax.get_lines():
    if line.get_label() == "col1":
        line.set_linewidth(3.5)
        line.set_alpha(0.8)
        line.set_marker("x")
\end{lstlisting}

\subsubsection{Использование регулярных выражений и обращений по имени группы при обработке строк}

Привести столбец строкового типа к числовому типу с предварительной подготовкой строки по регулярному выражению можно так
\begin{lstlisting}[
style = ironpython,
numbers = none	
]
pd.to_numeric(
    logs.loc[:, "time"].replace( # НЕ .str.replace!
        to_replace=r"^.*?(\d+).*?$",
        value=r"\1",  #  обращение к первой группе
        regex=True,
    )
)
\end{lstlisting}


% Источники в "Газовой промышленности" нумеруются по мере упоминания 
\begin{thebibliography}{99}\addcontentsline{toc}{section}{Список литературы}
	\bibitem{beazley:python-2010}{\emph{Бизли Д.} Python. Подробный справочник. -- СПб.: Символ-Плюс, 2010. -- 864 с.}
	
	\bibitem{beazley:python_cookbook-2019}{\emph{Бизли Д.} Python. Книга рецептов. -- М.: ДМК Пресс., 2019. -- 648 с.}

    \bibitem{mckinney:pandas-2015}{\emph{Маккинли У.} Python и анализ данных, 2015. -- 482 с.}
	
	\bibitem{ramalho:python-2022}{\emph{Рамальо Л.} Python -- к вершинам мастерства: Лаконичное и эффективное программирование. -- М.: МК Пресс, 2022. -- 898 с.}
	
	\bibitem{heydt:pandas-2019}{\emph{Хейдт М., Груздев А.} Изучаем pandas. -- М.: ДМК Пресс, 2019. -- 682 с.}
	
	\bibitem{hostmann:scala-2013}{\emph{Хостманн К.} Scala для нетерпеливых. -- М.: ДМК Пресс, 2013. -- 408 с.}
\end{thebibliography}

%\listoffigures\addcontentsline{toc}{section}{Список иллюстраций}

%\lstlistoflistings\addcontentsline{toc}{section}{Список листингов}

\end{document}
